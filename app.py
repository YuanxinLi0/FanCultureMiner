import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import jieba
import re
from datetime import datetime
import os
import sys
import warnings
warnings.filterwarnings('ignore')
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¾®åšé¥­åœˆæ–‡åŒ–èˆ†æƒ…åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


# ç¼“å­˜æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_data(file_path):
    """åŠ è½½CSVæ•°æ®"""
    return pd.read_csv(file_path, encoding='utf-8')


# ç¼“å­˜æ¨¡å‹åŠ è½½
@st.cache_resource
def load_models():
    models = {}
    from gensim import models as gensim_models
    models['pos_lda'] = gensim_models.LdaModel.load('output/4.1/pos_lda_model')
    models['neg_lda'] = gensim_models.LdaModel.load('output/4.1/neg_lda_model')
    import joblib
    models['kmeans'] = joblib.load('output/4.2/km.pkl')
    return models


# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ¯ åŠŸèƒ½å¯¼èˆª")

    # åŠŸèƒ½é€‰æ‹©
    page = st.selectbox(
        "é€‰æ‹©åŠŸèƒ½æ¨¡å—",
        ["æ•°æ®æ¦‚è§ˆ", "æ•°æ®é¢„å¤„ç†", "æƒ…æ„Ÿåˆ†æ", "ä¸»é¢˜å»ºæ¨¡",
         "èšç±»åˆ†æ", "ç¤¾äº¤ç½‘ç»œåˆ†æ", "ç»¼åˆæŠ¥å‘Š"]
    )

    st.markdown("---")

    # æ•°æ®æºé€‰æ‹©
    st.subheader("ğŸ“ æ•°æ®æº")
    data_source = st.radio(
        "é€‰æ‹©æ•°æ®æ–‡ä»¶",
        ["åŸå§‹è¯„è®º", "å¤„ç†åæ•°æ®", "æƒ…æ„Ÿæ ‡æ³¨æ•°æ®", "æœ€ç»ˆè®­ç»ƒæ•°æ®"]
    )

    # æ˜ å°„æ–‡ä»¶è·¯å¾„
    file_mapping = {
        "åŸå§‹è¯„è®º": "data/comments.csv",
        "å¤„ç†åæ•°æ®": "data/processed_comments.csv",
        "æƒ…æ„Ÿæ ‡æ³¨æ•°æ®": "data/sentiment_processed_data.csv",
        "æœ€ç»ˆè®­ç»ƒæ•°æ®": "data/final_data_of_train.csv"
    }

    # åŠ è½½æ•°æ®
    if os.path.exists(file_mapping[data_source]):
        df = load_data(file_mapping[data_source])
        st.success(f"âœ… å·²åŠ è½½ {len(df)} æ¡æ•°æ®")
    else:
        st.error("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        df = None

# ä¸»ç•Œé¢æ ‡é¢˜
st.title("ğŸ“Š å¾®åšé¥­åœˆæ–‡åŒ–èˆ†æƒ…åˆ†æç³»ç»Ÿ")
st.markdown("---")
# æ•°æ®æ¦‚è§ˆé¡µé¢
if page == "æ•°æ®æ¦‚è§ˆ":
    st.header("ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")

    if df is not None:
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è¯„è®ºæ•°", f"{len(df):,}")

        with col2:
            if 'user_name' in df.columns:
                st.metric("ç”¨æˆ·æ•°", f"{df['user_name'].nunique():,}")

        with col3:
            if 'sentiment_score' in df.columns:
                avg_sentiment = df['sentiment_score'].mean()
                st.metric("å¹³å‡æƒ…æ„Ÿåˆ†æ•°", f"{avg_sentiment:.3f}")

        with col4:
            if 'like_count' in df.columns:
                total_likes = df['like_count'].sum()
                st.metric("æ€»ç‚¹èµæ•°", f"{total_likes:,}")
        # æ•°æ®é¢„è§ˆ
        st.subheader("ğŸ“‹ æ•°æ®é¢„è§ˆ")
        # åˆ—é€‰æ‹©
        if len(df.columns) > 5:
            selected_cols = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—",
                df.columns.tolist(),
                default=df.columns[:5].tolist()
            )
            if selected_cols:
                st.dataframe(df[selected_cols].head(100))
        else:
            st.dataframe(df.head(100))
        # åŸºæœ¬ç»Ÿè®¡
        st.subheader("ğŸ“Š åŸºæœ¬ç»Ÿè®¡")
        st.write(df.describe())
        # æ—¶é—´åˆ†å¸ƒ
        if 'comment_time' in df.columns:
            st.subheader("ğŸ“… æ—¶é—´åˆ†å¸ƒ")
            df['datetime'] = pd.to_datetime(df['comment_time'], errors='coerce')
            df['date'] = df['datetime'].dt.date

            daily_counts = df.groupby('date').size()

            fig, ax = plt.subplots(figsize=(12, 6))
            daily_counts.plot(kind='bar', ax=ax)
            ax.set_title('æ¯æ—¥è¯„è®ºæ•°é‡åˆ†å¸ƒ')
            ax.set_xlabel('æ—¥æœŸ')
            ax.set_ylabel('è¯„è®ºæ•°')
            plt.xticks(rotation=45)
            st.pyplot(fig)

# æ•°æ®é¢„å¤„ç†é¡µé¢
elif page == "æ•°æ®é¢„å¤„ç†":
    st.header("ğŸ”§ æ•°æ®é¢„å¤„ç†")

    if df is not None:
        # é¢„å¤„ç†é€‰é¡¹
        st.subheader("âš™ï¸ é¢„å¤„ç†é€‰é¡¹")

        col1, col2 = st.columns(2)

        with col1:
            clean_text = st.checkbox("æ–‡æœ¬æ¸…æ´—", value=True)
            segment_text = st.checkbox("ä¸­æ–‡åˆ†è¯", value=True)
            remove_stopwords = st.checkbox("å»é™¤åœç”¨è¯", value=True)

        with col2:
            sentiment_analysis = st.checkbox("æƒ…æ„Ÿåˆ†æ", value=True)
            remove_duplicates = st.checkbox("å»é™¤é‡å¤", value=True)

        if st.button("ğŸš€ å¼€å§‹é¢„å¤„ç†"):
            with st.spinner("æ­£åœ¨å¤„ç†..."):
                progress_bar = st.progress(0)
                # æ–‡æœ¬æ¸…æ´—
                if clean_text and 'text' in df.columns:
                    progress_bar.progress(20)
                    st.info("æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ¸…æ´—...")

                    def clean_text_func(text):
                        if not isinstance(text, str):
                            return ""
                        text = re.sub(r'http[s]?://\S+|www\.\S+', '', text)
                        text = re.sub(r'<.*?>', '', text)
                        text = re.sub(r'[\U00010000-\U0010ffff]', '', text)
                        text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
                        text = re.sub(r'\s+', ' ', text).strip()
                        return text

                    df['cleaned_text'] = df['text'].apply(clean_text_func)
                # åˆ†è¯
                if segment_text and 'cleaned_text' in df.columns:
                    progress_bar.progress(40)
                    st.info("æ­£åœ¨è¿›è¡Œä¸­æ–‡åˆ†è¯...")
                    # åŠ è½½åœç”¨è¯
                    with open('tools/stopword.txt', 'r', encoding='utf-8') as f:
                        stopwords = set([line.strip() for line in f])
                    def segment_func(text):
                        words = jieba.lcut(text)
                        if remove_stopwords:
                            words = [w for w in words if w not in stopwords and len(w.strip()) >= 2]
                        return words
                    df['segmented'] = df['cleaned_text'].apply(segment_func)
                    df['segmented_text'] = df['segmented'].apply(lambda x: ' '.join(x))

                # æƒ…æ„Ÿåˆ†æ
                if sentiment_analysis:
                    progress_bar.progress(60)
                    st.info("æ­£åœ¨è¿›è¡Œæƒ…æ„Ÿåˆ†æ...")
                    from snownlp import SnowNLP

                    df['sentiment_score'] = df['cleaned_text'].apply(
                        lambda x: SnowNLP(x).sentiments if x else 0
                    )
                    # æƒ…æ„Ÿåˆ†ç±»è§„åˆ™
                    df['sentiment_category'] = df['sentiment_score'].apply(
                        lambda x: 1 if x > 0 else (0 if x < 0 else 2)  # å¤§äº0ä¸ºç§¯æï¼Œå°äº0ä¸ºæ¶ˆæï¼Œç­‰äº0ä¸ºä¸­æ€§
                    )

                # å»é‡
                if remove_duplicates and 'cleaned_text' in df.columns:
                    progress_bar.progress(80)
                    st.info("æ­£åœ¨å»é™¤é‡å¤æ•°æ®...")
                    original_len = len(df)
                    df = df.drop_duplicates(subset=['cleaned_text'], keep='first')
                    st.success(f"å»é™¤äº† {original_len - len(df)} æ¡é‡å¤æ•°æ®")

                progress_bar.progress(100)
                st.success("âœ… é¢„å¤„ç†å®Œæˆï¼")

                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“Š é¢„å¤„ç†ç»“æœ")
                st.dataframe(df.head(50))

                # ä¿å­˜é€‰é¡¹
                if st.button("ğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®"):
                    output_path = f"data/preprocessed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    df.to_csv(output_path, index=False, encoding='utf-8')
                    st.success(f"æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

# æƒ…æ„Ÿåˆ†æé¡µé¢
elif page == "æƒ…æ„Ÿåˆ†æ":
    st.header("ğŸ’­ æƒ…æ„Ÿåˆ†æ")

    if df is not None:
        # æ£€æŸ¥å¹¶ç¡®å®šæƒ…æ„Ÿåˆ†æ•°åˆ—
        sentiment_col = None
        sentiment_display_name = None

        # æ£€æŸ¥å¯èƒ½çš„æƒ…æ„Ÿåˆ†æ•°åˆ—
        if 'sentiment_score' in df.columns:
            sentiment_col = 'sentiment_score'
            sentiment_display_name = 'æƒ…æ„Ÿåˆ†æ•°'
        elif 'sentiment_category' in df.columns:
            # å¦‚æœåªæœ‰ç±»åˆ«ï¼Œå¯ä»¥åŸºäºç±»åˆ«åˆ›å»ºç®€å•çš„åˆ†æ•°
            st.info("æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†æ•°åˆ—ï¼ŒåŸºäºæƒ…æ„Ÿç±»åˆ«ç”Ÿæˆåˆ†æ•°...")
            df['sentiment_score_generated'] = df['sentiment_category'].map({0: 0.2, 1: 0.8, 2: 0.5})
            sentiment_col = 'sentiment_score_generated'
            sentiment_display_name = 'ç”Ÿæˆçš„æƒ…æ„Ÿåˆ†æ•°'
        else:
            st.warning("âš ï¸ å½“å‰æ•°æ®ä¸­æ²¡æœ‰æƒ…æ„Ÿåˆ†æç»“æœï¼Œè¯·å…ˆåœ¨'æ•°æ®é¢„å¤„ç†'ä¸­è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
            st.stop()

        # ç¡®ä¿æƒ…æ„Ÿåˆ†æ•°åœ¨0-1èŒƒå›´å†…
        if df[sentiment_col].min() < 0:
            # å¦‚æœæ˜¯centeredç‰ˆæœ¬ï¼ˆ-0.5åˆ°0.5ï¼‰ï¼Œè½¬æ¢å›0-1
            df['sentiment_score_normalized'] = df[sentiment_col] + 0.5
            sentiment_col = 'sentiment_score_normalized'
            sentiment_display_name = 'æ ‡å‡†åŒ–æƒ…æ„Ÿåˆ†æ•°'

        # æƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡
        col1, col2, col3 = st.columns(3)

        with col1:
            positive_ratio = (df[sentiment_col] > 0.6).mean()
            st.metric("æ­£é¢æ¯”ä¾‹", f"{positive_ratio:.1%}")

        with col2:
            neutral_ratio = ((df[sentiment_col] >= 0.4) & (df[sentiment_col] <= 0.6)).mean()
            st.metric("ä¸­æ€§æ¯”ä¾‹", f"{neutral_ratio:.1%}")

        with col3:
            negative_ratio = (df[sentiment_col] < 0.4).mean()
            st.metric("è´Ÿé¢æ¯”ä¾‹", f"{negative_ratio:.1%}")

        # æƒ…æ„Ÿåˆ†å¸ƒå›¾
        st.subheader("ğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒå¯è§†åŒ–")

        col1, col2 = st.columns(2)

        with col1:
            # æƒ…æ„Ÿåˆ†æ•°ç›´æ–¹å›¾
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.hist(df[sentiment_col], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            ax.axvline(df[sentiment_col].mean(), color='red', linestyle='--',
                       label=f'å¹³å‡å€¼: {df[sentiment_col].mean():.3f}')
            ax.set_xlabel(sentiment_display_name)
            ax.set_ylabel('é¢‘æ¬¡')
            ax.set_title(f'{sentiment_display_name}åˆ†å¸ƒ')
            ax.legend()
            st.pyplot(fig)

        with col2:
            # æƒ…æ„Ÿç±»åˆ«é¥¼å›¾
            sentiment_counts = pd.Series({
                'æ­£é¢': (df[sentiment_col] > 0.6).sum(),
                'ä¸­æ€§': ((df[sentiment_col] >= 0.4) & (df[sentiment_col] <= 0.6)).sum(),
                'è´Ÿé¢': (df[sentiment_col] < 0.4).sum()
            })

            fig, ax = plt.subplots(figsize=(8, 6))
            colors = ['#4CAF50', '#FFC107', '#F44336']
            ax.pie(sentiment_counts.values, labels=sentiment_counts.index,
                   autopct='%1.1f%%', colors=colors, startangle=90)
            ax.set_title('æƒ…æ„Ÿç±»åˆ«åˆ†å¸ƒ')
            st.pyplot(fig)

        # æ—¶é—´è¶‹åŠ¿åˆ†æ
        time_col = None
        if 'datetime' in df.columns:
            time_col = 'datetime'
        elif 'comment_time' in df.columns:
            df['datetime'] = pd.to_datetime(df['comment_time'], errors='coerce')
            time_col = 'datetime'

        if time_col and df[time_col].notna().any():
            st.subheader("ğŸ“ˆ æƒ…æ„Ÿæ—¶é—´è¶‹åŠ¿")

            # æŒ‰æ—¥æœŸèšåˆ
            df['date'] = pd.to_datetime(df[time_col]).dt.date
            daily_sentiment = df.groupby('date')[sentiment_col].agg(['mean', 'count'])

            fig, ax1 = plt.subplots(figsize=(12, 6))

            # æƒ…æ„Ÿå‡å€¼
            ax1.plot(daily_sentiment.index, daily_sentiment['mean'],
                     'b-', marker='o', label='å¹³å‡æƒ…æ„Ÿåˆ†æ•°')
            ax1.set_xlabel('æ—¥æœŸ')
            ax1.set_ylabel('å¹³å‡æƒ…æ„Ÿåˆ†æ•°', color='b')
            ax1.tick_params(axis='y', labelcolor='b')
            ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
            ax1.legend(loc='upper left')

            # è¯„è®ºæ•°é‡
            ax2 = ax1.twinx()
            ax2.bar(daily_sentiment.index, daily_sentiment['count'],
                    alpha=0.3, color='green', label='è¯„è®ºæ•°é‡')
            ax2.set_ylabel('è¯„è®ºæ•°é‡', color='g')
            ax2.tick_params(axis='y', labelcolor='g')
            ax2.legend(loc='upper right')

            plt.title('æƒ…æ„Ÿè¶‹åŠ¿ä¸è¯„è®ºé‡å˜åŒ–')
            fig.autofmt_xdate()
            st.pyplot(fig)

        # æƒ…æ„Ÿåˆ†æè¯¦æƒ…
        st.subheader("ğŸ“ æƒ…æ„Ÿåˆ†æè¯¦æƒ…")

        # é€‰æ‹©æƒ…æ„Ÿç±»åˆ«æŸ¥çœ‹
        sentiment_type = st.selectbox(
            "é€‰æ‹©è¦æŸ¥çœ‹çš„æƒ…æ„Ÿç±»åˆ«",
            ["å…¨éƒ¨", "æ­£é¢", "ä¸­æ€§", "è´Ÿé¢"]
        )

        if sentiment_type == "æ­£é¢":
            filtered_df = df[df[sentiment_col] > 0.6]
        elif sentiment_type == "ä¸­æ€§":
            filtered_df = df[(df[sentiment_col] >= 0.4) & (df[sentiment_col] <= 0.6)]
        elif sentiment_type == "è´Ÿé¢":
            filtered_df = df[df[sentiment_col] < 0.4]
        else:
            filtered_df = df

        # æ˜¾ç¤ºæ ·ä¾‹
        text_col = None
        if 'text' in filtered_df.columns:
            text_col = 'text'
        elif 'cleaned_text' in filtered_df.columns:
            text_col = 'cleaned_text'

        if text_col:
            st.write(f"å…± {len(filtered_df)} æ¡{sentiment_type}è¯„è®º")

            # éšæœºæ˜¾ç¤ºä¸€äº›è¯„è®º
            sample_size = min(10, len(filtered_df))
            if sample_size > 0:
                samples = filtered_df.sample(n=sample_size)
                for _, row in samples.iterrows():
                    with st.expander(f"æƒ…æ„Ÿåˆ†æ•°: {row[sentiment_col]:.3f}"):
                        st.write(row[text_col])
                        if 'user_name' in row:
                            st.caption(f"ç”¨æˆ·: {row['user_name']}")
                        if 'like_count' in row:
                            st.caption(f"ğŸ‘ {row['like_count']} | ğŸ’¬ {row.get('reply_count', 0)}")

# ä¸»é¢˜å»ºæ¨¡é¡µé¢
elif page == "ä¸»é¢˜å»ºæ¨¡":
    st.header("ğŸ¯ ä¸»é¢˜å»ºæ¨¡")

    # æ£€æŸ¥å·²æœ‰çš„LDAç»“æœ
    if os.path.exists('output/4.1/pos_lda_visualization.html'):
        st.subheader("ğŸ“Š å·²æœ‰ä¸»é¢˜å»ºæ¨¡ç»“æœ")

        tab1, tab2 = st.tabs(["æ­£é¢è¯„è®ºä¸»é¢˜", "è´Ÿé¢è¯„è®ºä¸»é¢˜"])

        with tab1:
            st.write("æ­£é¢è¯„è®ºLDAä¸»é¢˜åˆ†æ")

            # æ˜¾ç¤ºHTMLå¯è§†åŒ–
            with open('output/4.1/pos_lda_visualization.html', 'r', encoding='utf-8') as f:
                html_content = f.read()

            st.components.v1.html(html_content, height=800, scrolling=True)

            # æ˜¾ç¤ºä¸€è‡´æ€§å›¾
            if os.path.exists('output/4.1/pos_coherence_plot.png'):
                st.image('output/4.1/pos_coherence_plot.png',
                         caption='æ­£é¢è¯„è®ºä¸»é¢˜ä¸€è‡´æ€§åˆ†æ')

        with tab2:
            st.write("è´Ÿé¢è¯„è®ºLDAä¸»é¢˜åˆ†æ")

            # æ˜¾ç¤ºHTMLå¯è§†åŒ–
            with open('output/4.1/neg_lda_visualization.html', 'r', encoding='utf-8') as f:
                html_content = f.read()

            st.components.v1.html(html_content, height=800, scrolling=True)

            # æ˜¾ç¤ºä¸€è‡´æ€§å›¾
            if os.path.exists('output/4.1/neg_coherence_plot.png'):
                st.image('output/4.1/neg_coherence_plot.png',
                         caption='è´Ÿé¢è¯„è®ºä¸»é¢˜ä¸€è‡´æ€§åˆ†æ')

    # æ–°å»ºä¸»é¢˜å»ºæ¨¡
    st.subheader("ğŸ†• æ–°å»ºä¸»é¢˜æ¨¡å‹")

    if df is not None and 'segmented' in df.columns:
        col1, col2 = st.columns(2)

        with col1:
            num_topics = st.slider("ä¸»é¢˜æ•°é‡", 2, 10, 5)
            sentiment_filter = st.selectbox(
                "é€‰æ‹©æƒ…æ„Ÿç±»åˆ«",
                ["å…¨éƒ¨", "æ­£é¢", "è´Ÿé¢"]
            )

        with col2:
            max_features = st.slider("æœ€å¤§ç‰¹å¾æ•°", 100, 1000, 500)
            iterations = st.slider("è¿­ä»£æ¬¡æ•°", 10, 50, 20)

        if st.button("ğŸ¯ å¼€å§‹ä¸»é¢˜å»ºæ¨¡"):
            with st.spinner("æ­£åœ¨è¿›è¡Œä¸»é¢˜å»ºæ¨¡..."):
                try:
                    from gensim import corpora, models

                    # è¿‡æ»¤æ•°æ®
                    if 'sentiment_score' in df.columns:
                        sentiment_col = 'sentiment_score'
                    elif 'sentiment_category' in df.columns:
                        # åŸºäºç±»åˆ«è¿‡æ»¤
                        if sentiment_filter == "æ­£é¢":
                            texts = df[df['sentiment_category'] == 1]['segmented'].dropna()
                        elif sentiment_filter == "è´Ÿé¢":
                            texts = df[df['sentiment_category'] == 0]['segmented'].dropna()
                        else:
                            texts = df['segmented'].dropna()
                    else:
                        texts = df['segmented'].dropna()

                    if 'sentiment_score' in df.columns:
                        if sentiment_filter == "æ­£é¢":
                            texts = df[df['sentiment_score'] > 0.6]['segmented'].dropna()
                        elif sentiment_filter == "è´Ÿé¢":
                            texts = df[df['sentiment_score'] < 0.4]['segmented'].dropna()

                    # å‡†å¤‡è¯­æ–™
                    texts = [text for text in texts if isinstance(text, list) and len(text) > 0]

                    if len(texts) < 10:
                        st.error("æ–‡æœ¬æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10æ¡")
                    else:
                        # åˆ›å»ºè¯å…¸å’Œè¯­æ–™åº“
                        dictionary = corpora.Dictionary(texts)
                        corpus = [dictionary.doc2bow(text) for text in texts]

                        # è®­ç»ƒLDAæ¨¡å‹
                        lda_model = models.LdaModel(
                            corpus,
                            num_topics=num_topics,
                            id2word=dictionary,
                            passes=iterations,
                            random_state=42
                        )

                        # æ˜¾ç¤ºä¸»é¢˜
                        st.success("âœ… ä¸»é¢˜å»ºæ¨¡å®Œæˆï¼")

                        for i in range(num_topics):
                            st.write(f"**ä¸»é¢˜ {i + 1}:**")
                            words = lda_model.print_topic(i, 10)
                            st.write(words)
                            st.write("---")

                except Exception as e:
                    st.error(f"ä¸»é¢˜å»ºæ¨¡å¤±è´¥: {str(e)}")

# èšç±»åˆ†æé¡µé¢
elif page == "èšç±»åˆ†æ":
    st.header("ğŸ” èšç±»åˆ†æ")

    # æ˜¾ç¤ºå·²æœ‰ç»“æœ
    col1, col2 = st.columns(2)

    with col1:
        if os.path.exists('output/4.2/dbscan_opinion_leaders_improved.png'):
            st.subheader("DBSCANèšç±»ç»“æœ")
            st.image('output/4.2/dbscan_opinion_leaders_improved.png')

    with col2:
        if os.path.exists('output/4.2/kmeans_opinion_leaders.png'):
            st.subheader("K-Meansèšç±»ç»“æœ")
            st.image('output/4.2/kmeans_opinion_leaders.png')

    # æ–°å»ºèšç±»åˆ†æ
    st.subheader("ğŸ†• æ–°å»ºèšç±»åˆ†æ")

    if df is not None:
        col1, col2 = st.columns(2)

        with col1:
            cluster_method = st.selectbox("èšç±»æ–¹æ³•", ["K-Means", "DBSCAN"])

            if cluster_method == "K-Means":
                n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
            else:
                eps = st.slider("DBSCAN epså‚æ•°", 0.1, 2.0, 0.5, 0.1)
                min_samples = st.slider("DBSCAN min_samples", 2, 20, 5)

        with col2:
            feature_type = st.selectbox("ç‰¹å¾ç±»å‹", ["TF-IDF", "Word2Vec"])
            max_features = st.slider("æœ€å¤§ç‰¹å¾æ•°", 100, 2000, 500)

        if st.button("ğŸ” å¼€å§‹èšç±»"):
            with st.spinner("æ­£åœ¨è¿›è¡Œèšç±»åˆ†æ..."):
                try:
                    from sklearn.feature_extraction.text import TfidfVectorizer
                    from sklearn.cluster import KMeans, DBSCAN
                    from sklearn.decomposition import PCA

                    # å‡†å¤‡æ–‡æœ¬æ•°æ®
                    if 'segmented_text' in df.columns:
                        texts = df['segmented_text'].fillna('')
                    elif 'cleaned_text' in df.columns:
                        texts = df['cleaned_text'].fillna('')
                    else:
                        st.error("æœªæ‰¾åˆ°å¤„ç†åçš„æ–‡æœ¬æ•°æ®")
                        st.stop()

                    # ç‰¹å¾æå–
                    vectorizer = TfidfVectorizer(max_features=max_features)
                    features = vectorizer.fit_transform(texts)

                    # èšç±»
                    if cluster_method == "K-Means":
                        model = KMeans(n_clusters=n_clusters, random_state=42)
                    else:
                        model = DBSCAN(eps=eps, min_samples=min_samples)

                    labels = model.fit_predict(features)

                    # PCAé™ç»´å¯è§†åŒ–
                    pca = PCA(n_components=2)
                    features_2d = pca.fit_transform(features.toarray())

                    # ç»˜åˆ¶ç»“æœ
                    fig, ax = plt.subplots(figsize=(10, 8))
                    scatter = ax.scatter(features_2d[:, 0], features_2d[:, 1],
                                         c=labels, cmap='tab10', alpha=0.6)
                    ax.set_title(f'{cluster_method}èšç±»ç»“æœ')
                    ax.set_xlabel('ä¸»æˆåˆ†1')
                    ax.set_ylabel('ä¸»æˆåˆ†2')
                    plt.colorbar(scatter, ax=ax)
                    st.pyplot(fig)

                    # èšç±»ç»Ÿè®¡
                    st.subheader("ğŸ“Š èšç±»ç»Ÿè®¡")
                    cluster_counts = pd.Series(labels).value_counts().sort_index()

                    fig, ax = plt.subplots(figsize=(8, 6))
                    cluster_counts.plot(kind='bar', ax=ax)
                    ax.set_title('å„èšç±»å¤§å°')
                    ax.set_xlabel('èšç±»ID')
                    ax.set_ylabel('æ ·æœ¬æ•°')
                    st.pyplot(fig)

                    # æ˜¾ç¤ºèšç±»è¯¦æƒ…
                    st.subheader("ğŸ“ èšç±»è¯¦æƒ…")
                    for cluster_id in sorted(cluster_counts.index):
                        if cluster_id != -1:  # è·³è¿‡å™ªå£°ç‚¹
                            cluster_data = df[labels == cluster_id]
                            with st.expander(f"èšç±» {cluster_id} ({len(cluster_data)} ä¸ªæ ·æœ¬)"):
                                # æ£€æŸ¥å¯ç”¨çš„æƒ…æ„Ÿåˆ—
                                if 'sentiment_score' in cluster_data.columns:
                                    st.write(f"å¹³å‡æƒ…æ„Ÿåˆ†æ•°: {cluster_data['sentiment_score'].mean():.3f}")
                                elif 'sentiment_category' in cluster_data.columns:
                                    positive_ratio = (cluster_data['sentiment_category'] == 1).mean()
                                    st.write(f"æ­£é¢æ¯”ä¾‹: {positive_ratio:.2%}")

                                # æ˜¾ç¤ºæ–‡æœ¬æ ·ä¾‹
                                text_col = None
                                if 'text' in cluster_data.columns:
                                    text_col = 'text'
                                elif 'cleaned_text' in cluster_data.columns:
                                    text_col = 'cleaned_text'

                                if text_col:
                                    st.write("æ ·ä¾‹æ–‡æœ¬:")
                                    samples = cluster_data.sample(min(3, len(cluster_data)))
                                    for _, row in samples.iterrows():
                                        st.write(f"- {row[text_col][:100]}...")

                except Exception as e:
                    st.error(f"èšç±»åˆ†æå¤±è´¥: {str(e)}")

# ç¤¾äº¤ç½‘ç»œåˆ†æé¡µé¢
elif page == "ç¤¾äº¤ç½‘ç»œåˆ†æ":
    st.header("ğŸŒ ç¤¾äº¤ç½‘ç»œåˆ†æ")

    # æ˜¾ç¤ºå·²æœ‰ç»“æœ
    if os.path.exists('output/4.3/influence_network_analysis.png'):
        st.subheader("ğŸ“Š å½±å“åŠ›ç½‘ç»œåˆ†æ")
        st.image('output/4.3/influence_network_analysis.png')

    if os.path.exists('output/4.3/folium_heatmap.html'):
        st.subheader("ğŸ—ºï¸ åœ°ç†åˆ†å¸ƒçƒ­åŠ›å›¾")
        with open('output/4.3/folium_heatmap.html', 'r', encoding='utf-8') as f:
            html_content = f.read()
        st.components.v1.html(html_content, height=600, scrolling=True)

    # ç”¨æˆ·å½±å“åŠ›åˆ†æ
    if df is not None and 'user_name' in df.columns:
        st.subheader("ğŸ‘¥ ç”¨æˆ·å½±å“åŠ›åˆ†æ")

        # è®¡ç®—ç”¨æˆ·ç»Ÿè®¡
        agg_dict = {'comment_id': 'count'}

        if 'like_count' in df.columns:
            agg_dict['like_count'] = 'sum'
        if 'reply_count' in df.columns:
            agg_dict['reply_count'] = 'sum'

        # æ£€æŸ¥æƒ…æ„Ÿåˆ†æ•°åˆ—
        sentiment_col = None
        if 'sentiment_score' in df.columns:
            sentiment_col = 'sentiment_score'
            agg_dict['sentiment_score'] = 'mean'
        elif 'sentiment_category' in df.columns:
            # è®¡ç®—æ­£é¢æ¯”ä¾‹ä½œä¸ºæƒ…æ„ŸæŒ‡æ ‡
            df['positive_flag'] = (df['sentiment_category'] == 1).astype(int)
            agg_dict['positive_flag'] = 'mean'

        user_stats = df.groupby('user_name').agg(agg_dict)

        # é‡å‘½ååˆ—
        user_stats = user_stats.rename(columns={'comment_id': 'comment_count'})

        # è®¡ç®—å½±å“åŠ›åˆ†æ•°
        if 'like_count' in user_stats.columns and 'reply_count' in user_stats.columns:
            user_stats['influence_score'] = (
                    user_stats['like_count'] * 0.5 +
                    user_stats['reply_count'] * 0.3 +
                    user_stats['comment_count'] * 0.2
            )
        else:
            # ç®€å•åŸºäºè¯„è®ºæ•°çš„å½±å“åŠ›
            user_stats['influence_score'] = user_stats['comment_count']

        # Topç”¨æˆ·
        top_users = user_stats.nlargest(10, 'influence_score')

        # æ˜¾ç¤ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # å½±å“åŠ›æ’å
        top_users['influence_score'].plot(kind='barh', ax=ax1)
        ax1.set_title('Top 10 å½±å“åŠ›ç”¨æˆ·')
        ax1.set_xlabel('å½±å“åŠ›åˆ†æ•°')

        # æƒ…æ„Ÿvså½±å“åŠ›
        if sentiment_col in user_stats.columns:
            ax2.scatter(user_stats['influence_score'], user_stats[sentiment_col], alpha=0.6)
            ax2.set_xlabel('å½±å“åŠ›åˆ†æ•°')
            ax2.set_ylabel('å¹³å‡æƒ…æ„Ÿåˆ†æ•°')
            ax2.set_title('ç”¨æˆ·å½±å“åŠ›ä¸æƒ…æ„Ÿå€¾å‘')
            ax2.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)
        elif 'positive_flag' in user_stats.columns:
            ax2.scatter(user_stats['influence_score'], user_stats['positive_flag'], alpha=0.6)
            ax2.set_xlabel('å½±å“åŠ›åˆ†æ•°')
            ax2.set_ylabel('æ­£é¢è¯„è®ºæ¯”ä¾‹')
            ax2.set_title('ç”¨æˆ·å½±å“åŠ›ä¸æ­£é¢å€¾å‘')
            ax2.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)

        st.pyplot(fig)

        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        st.subheader("ğŸ“‹ å½±å“åŠ›ç”¨æˆ·è¯¦æƒ…")
        st.dataframe(top_users.round(2))

# ç»¼åˆæŠ¥å‘Šé¡µé¢
elif page == "ç»¼åˆæŠ¥å‘Š":
    st.header("ğŸ“‘ ç»¼åˆåˆ†ææŠ¥å‘Š")

    if df is not None:
        # ç”ŸæˆæŠ¥å‘Š
        report = "# å¾®åšé¥­åœˆæ–‡åŒ–èˆ†æƒ…åˆ†æç³»ç»Ÿç»¼åˆæŠ¥å‘Š\n\n"
        report += f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        # æ•°æ®æ¦‚è§ˆ
        report += "## 1. æ•°æ®æ¦‚è§ˆ\n\n"
        report += f"- æ€»è¯„è®ºæ•°: {len(df):,} æ¡\n"

        if 'user_name' in df.columns:
            report += f"- æ´»è·ƒç”¨æˆ·æ•°: {df['user_name'].nunique():,} äºº\n"

        if 'datetime' in df.columns:
            date_range = f"{df['datetime'].min()} è‡³ {df['datetime'].max()}"
            report += f"- æ—¶é—´èŒƒå›´: {date_range}\n"

        # æƒ…æ„Ÿåˆ†æ
        sentiment_col = None
        if 'sentiment_score' in df.columns:
            sentiment_col = 'sentiment_score'
        elif 'sentiment_category' in df.columns:
            # åŸºäºç±»åˆ«ç”Ÿæˆç®€å•ç»Ÿè®¡
            report += "\n## 2. æƒ…æ„Ÿåˆ†æ\n\n"
            if 'sentiment_category' in df.columns:
                sentiment_counts = df['sentiment_category'].value_counts()
                if 1 in sentiment_counts:
                    report += f"- æ­£é¢è¯„è®º: {sentiment_counts.get(1, 0)} æ¡\n"
                if 0 in sentiment_counts:
                    report += f"- è´Ÿé¢è¯„è®º: {sentiment_counts.get(0, 0)} æ¡\n"
                if 2 in sentiment_counts:
                    report += f"- ä¸­æ€§è¯„è®º: {sentiment_counts.get(2, 0)} æ¡\n"

        if sentiment_col:
            report += "\n## 2. æƒ…æ„Ÿåˆ†æ\n\n"
            positive_ratio = (df[sentiment_col] > 0.6).mean()
            neutral_ratio = ((df[sentiment_col] >= 0.4) & (df[sentiment_col] <= 0.6)).mean()
            negative_ratio = (df[sentiment_col] < 0.4).mean()

            report += f"- æ­£é¢è¯„è®º: {positive_ratio:.1%}\n"
            report += f"- ä¸­æ€§è¯„è®º: {neutral_ratio:.1%}\n"
            report += f"- è´Ÿé¢è¯„è®º: {negative_ratio:.1%}\n"
            report += f"- å¹³å‡æƒ…æ„Ÿåˆ†æ•°: {df[sentiment_col].mean():.3f}\n"

        # çƒ­é—¨è¯é¢˜
        if 'segmented' in df.columns:
            report += "\n## 3. çƒ­é—¨è¯é¢˜\n\n"
            all_words = []
            for words in df['segmented']:
                if isinstance(words, list):
                    all_words.extend(words)

            if all_words:
                word_freq = pd.Series(all_words).value_counts().head(10)
                for word, count in word_freq.items():
                    report += f"- {word}: {count} æ¬¡\n"

        # ç»“è®ºä¸å»ºè®®
        report += "\n## 4. ç»“è®ºä¸å»ºè®®\n\n"

        if sentiment_col:
            avg_sentiment = df[sentiment_col].mean()
            if avg_sentiment > 0.6:
                report += "- æ•´ä½“èˆ†æƒ…åæ­£é¢ï¼Œå“ç‰Œå½¢è±¡è‰¯å¥½\n"
                report += "- å»ºè®®ç»§ç»­ä¿æŒç°æœ‰ç­–ç•¥ï¼ŒåŠ å¼ºæ­£é¢å†…å®¹ä¼ æ’­\n"
            elif avg_sentiment < 0.4:
                report += "- æ•´ä½“èˆ†æƒ…åè´Ÿé¢ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨\n"
                report += "- å»ºè®®åŠæ—¶å›åº”è´Ÿé¢åé¦ˆï¼Œæ”¹å–„äº§å“æˆ–æœåŠ¡\n"
            else:
                report += "- æ•´ä½“èˆ†æƒ…è¾ƒä¸ºä¸­æ€§\n"
                report += "- å»ºè®®åŠ å¼ºäº’åŠ¨ï¼Œæå‡ç”¨æˆ·å‚ä¸åº¦\n"

        # æ˜¾ç¤ºæŠ¥å‘Š
        st.markdown(report)

        # ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š",
            data=report,
            file_name=f"èˆ†æƒ…åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )

        # æ˜¾ç¤ºæ‰€æœ‰å›¾è¡¨
        st.subheader("ğŸ“Š åˆ†æå›¾è¡¨æ±‡æ€»")

        # å±•ç¤ºoutputç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
        output_dirs = ['output/2', 'output/3.3', 'output/4.1', 'output/4.2', 'output/4.3']

        for dir_path in output_dirs:
            if os.path.exists(dir_path):
                st.write(f"**{dir_path} ç›®å½•ä¸‹çš„å›¾è¡¨:**")

                image_files = [f for f in os.listdir(dir_path)
                               if f.endswith(('.png', '.jpg', '.jpeg'))]

                if image_files:
                    cols = st.columns(2)
                    for i, img_file in enumerate(image_files):
                        with cols[i % 2]:
                            img_path = os.path.join(dir_path, img_file)
                            st.image(img_path, caption=img_file, use_column_width=True)
                else:
                    st.write("- æ— å›¾è¡¨æ–‡ä»¶")

                st.write("---")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>å¾®åšé¥­åœˆæ–‡åŒ–èˆ†æƒ…åˆ†æç³»ç»Ÿ | åŸºäºStreamlitå¼€å‘ï¼ˆ22çº§æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯1ç­ 202205050107 æå…ƒé‘«ï¼‰</p>
    </div>
    """,
    unsafe_allow_html=True
)